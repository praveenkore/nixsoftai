# VulnGuard Environment Configuration Example
# Copy this file to .env and fill in your actual values

# OpenAI Configuration
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic Configuration
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# OpenRouter Configuration
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here

# Local LLM Configuration
# Path to your local model file (e.g., LLaMA, Mistral, Falcon)
LOCAL_LLM_MODEL_PATH=/path/to/your/model
LOCAL_LLM_MODEL_TYPE=llama
LOCAL_LLM_DEVICE=auto

# Ollama Configuration
# Ollama API endpoint (default: http://localhost:11434/api/generate)
OLLAMA_API_ENDPOINT=http://localhost:11434/api/generate
OLLAMA_MODEL=llama2

# VulnGuard Configuration
# Override default configuration values if needed
# VULNGUARD_CONFIG_PATH=/path/to/custom/config.yaml
# VULNGUARD_LOG_LEVEL=INFO
# VULNGUARD_LOG_FORMAT=json

# Notes:
# 1. Never commit .env file with real API keys to version control
# 2. Keep your API keys secret and secure
# 3. Rotate API keys regularly for security
# 4. Use environment variables for sensitive data in production
